{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разведочный анализ данных и разметка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 0: Подготовка\n",
    "1. Поскольку коммерческие данные получить быстро не удалось, было принято решение использовать публичные данные, доступные на [госзакупках](https://zakupki.gov.ru/epz/main/public/home.html).\n",
    "2. В связи с таким изменением подхода появилась необходимость переформулирования задачи, теперь она сформулирована так: \"Классификация договора в зависимости от предмета по второму уровню ОКПД2\". Классификатор ОКПД2 можно получить, например, [здесь](https://www.consultant.ru/document/cons_doc_LAW_163703/). Таким образом, цель изменилась до: по разделу предмета договора вернуть второй уровень кода ОКПД2.\n",
    "Важное замечание: поскольку предметов договора в данном случае может быть много, то мы имеем дело с многоклассовой классификацией.\n",
    "3. Датасет состоит из 200057 записей в формате JSON, содержащие три поля \"regNum\" - реестровый номер контракта, \"contractSubjectFull\" - полный текст предмета договора, \"OKPD2_codes\" - набор ОКПД2 кодов из договора. Датасет расположени по [адресу](https://www.kaggle.com/datasets/aldarovalexander/contracts/data). Сам датасет был получен путем парсинга части исполненных договоров за 2022 год, которые бы имели формат верный DOCX и разбора формализованной части договоров. Часть процесса получения, например, из графического представления договора верного текста предмета в данном исследовании опущена, поскольку для целей самого исследования не представляет интереса.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Импорт библиотек и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки загружены\n",
      "Текущая рабочая директория: /content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import kagglehub\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "\n",
    "# Настройка отображения\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Библиотеки загружены\")\n",
    "print(\"Текущая рабочая директория:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-665171045.py:7: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
      "  df = kagglehub.load_dataset(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'contracts' dataset.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-b74aa6dc-b8a8-4bfe-add3-acb780e41ec7\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>regNum</th>\n",
       "      <th>contractSubjectFull</th>\n",
       "      <th>OKPD2_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>166300031414000000</td>\n",
       "      <td>1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - об...</td>\n",
       "      <td>[43]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "      \n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b74aa6dc-b8a8-4bfe-add3-acb780e41ec7')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "      \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-b74aa6dc-b8a8-4bfe-add3-acb780e41ec7 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-b74aa6dc-b8a8-4bfe-add3-acb780e41ec7');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "  \n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "               regNum  \\\n",
       "0  166300031414000000   \n",
       "\n",
       "                                                                                                                                                                                       contractSubjectFull  \\\n",
       "0  1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - об...   \n",
       "\n",
       "  OKPD2_codes  \n",
       "0        [43]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "# Указываем конкретный файл для загрузки\n",
    "file_path = \"contracts_dataset_filtered.json\"\n",
    "\n",
    "# Load the latest version\n",
    "df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"aldarovalexander/contracts\",\n",
    "    file_path,\n",
    ")\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200057, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'contracts' dataset.\n",
      "=== ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ ===\n",
      "Размер датасета: (200057, 3)\n",
      "Колонки: ['regNum', 'contractSubjectFull', 'OKPD2_codes']\n",
      "\n",
      "Типы данных:\n",
      "regNum                  int64\n",
      "contractSubjectFull    object\n",
      "OKPD2_codes            object\n",
      "dtype: object\n",
      "\n",
      "=== ДЕТАЛЬНЫЙ АНАЛИЗ ===\n",
      "Общее количество записей: 200057\n",
      "Количество уникальных номеров контрактов: 38386\n",
      "\n",
      "=== АНАЛИЗ OKPD2 КОДОВ ===\n",
      "Всего OKPD2 кодов (с повторениями): 212039\n",
      "Уникальных OKPD2 кодов: 84\n",
      "\n",
      "Топ-10 самых частых OKPD2 кодов:\n",
      "OKPD2_codes\n",
      "21    36837\n",
      "10    28416\n",
      "32    21153\n",
      "26    10972\n",
      "20     7498\n",
      "01     7328\n",
      "43     6798\n",
      "17     6457\n",
      "22     6037\n",
      "68     4529\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== СТРУКТУРА OKPD2 КОДОВ ===\n",
      "Количество контрактов с одним OKPD2 кодом: 191281\n",
      "Количество контрактов с несколькими OKPD2 кодами: 8776\n",
      "Максимальное количество OKPD2 кодов в одном контракте: 11\n",
      "\n",
      "=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===\n",
      "regNum                 0\n",
      "contractSubjectFull    0\n",
      "OKPD2_codes            0\n",
      "dtype: int64\n",
      "\n",
      "=== АНАЛИЗ ТЕКСТОВЫХ ДАННЫХ ===\n",
      "Средняя длина contractSubjectFull: 872 символов\n",
      "Максимальная длина contractSubjectFull: 9398 символов\n",
      "Минимальная длина contractSubjectFull: 1 символов\n",
      "\n",
      "=== СТАТИСТИКА ПО КОЛОНКАМ ===\n",
      "Длина regNum:\n",
      "  Минимальная: 18\n",
      "  Максимальная: 19\n",
      "  Уникальные длины: [np.int64(18), np.int64(19)]\n",
      "\n",
      "=== ПРИМЕРЫ ДАННЫХ ===\n",
      "Первые 3 записи:\n",
      "\n",
      "Запись 1:\n",
      "  regNum: 166300031414000000\n",
      "  OKPD2_codes: ['43']\n",
      "  contractSubjectFull (первые 200 символов): 1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект...\n",
      "\n",
      "Запись 2:\n",
      "  regNum: 324300007314000000\n",
      "  OKPD2_codes: ['71']\n",
      "  contractSubjectFull (первые 200 символов): Исполнитель обязуется выполнить работу согласно Приложению № к Контракту и сдать ее результат Заказчику, а Заказчик обязуется принять результат работы и оплатить его. Качество работы Качество выполнен...\n",
      "\n",
      "Запись 3:\n",
      "  regNum: 366300032914000000\n",
      "  OKPD2_codes: ['21']\n",
      "  contractSubjectFull (первые 200 символов): 1.1. По настоящему контракту поставщик обязуется поставить и передать заказчику в срок, предусмотренный настоящим контрактом, лекарственные препараты (далее - товар) в соответствии со спецификацией (п...\n",
      "\n",
      "=== АНАЛИЗ КОМБИНАЦИЙ OKPD2 КОДОВ ===\n",
      "Уникальных комбинаций OKPD2 кодов: 1046\n",
      "Топ-5 самых частых комбинаций OKPD2 кодов:\n",
      "  ['21']: 36084 контрактов\n",
      "  ['10']: 26239 контрактов\n",
      "  ['32']: 19297 контрактов\n",
      "  ['26']: 10261 контрактов\n",
      "  ['43']: 6599 контрактов\n",
      "\n",
      "=== РАСПРЕДЕЛЕНИЕ КОЛИЧЕСТВА OKPD2 КОДОВ ===\n",
      "  1 код(ов): 191281 контрактов (95.6%)\n",
      "  2 код(ов): 6680 контрактов (3.3%)\n",
      "  3 код(ов): 1355 контрактов (0.7%)\n",
      "  4 код(ов): 514 контрактов (0.3%)\n",
      "  5 код(ов): 142 контрактов (0.1%)\n",
      "  6 код(ов): 52 контрактов (0.0%)\n",
      "  7 код(ов): 22 контрактов (0.0%)\n",
      "  8 код(ов): 4 контрактов (0.0%)\n",
      "  9 код(ов): 4 контрактов (0.0%)\n",
      "  11 код(ов): 3 контрактов (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Используем новый метод dataset_load()\n",
    "df = kagglehub.dataset_load(\n",
    "    kagglehub.KaggleDatasetAdapter.PANDAS,\n",
    "    \"aldarovalexander/contracts\",\n",
    "    \"contracts_dataset_filtered.json\",\n",
    ")\n",
    "\n",
    "print(\"=== ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ ===\")\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Колонки: {list(df.columns)}\")\n",
    "print(\"\\nТипы данных:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Преобразуем regNum в строковый тип\n",
    "df['regNum'] = df['regNum'].astype(str)\n",
    "\n",
    "# Более детальный анализ\n",
    "print(\"\\n=== ДЕТАЛЬНЫЙ АНАЛИЗ ===\")\n",
    "print(f\"Общее количество записей: {len(df)}\")\n",
    "print(f\"Количество уникальных номеров контрактов: {df['regNum'].nunique()}\")\n",
    "\n",
    "# Правильный анализ OKPD2 кодов (списков)\n",
    "print(\"\\n=== АНАЛИЗ OKPD2 КОДОВ ===\")\n",
    "# Развернем списки OKPD2 кодов для анализа\n",
    "all_okpd2_codes = df['OKPD2_codes'].explode()\n",
    "print(f\"Всего OKPD2 кодов (с повторениями): {len(all_okpd2_codes)}\")\n",
    "print(f\"Уникальных OKPD2 кодов: {all_okpd2_codes.nunique()}\")\n",
    "print(\"\\nТоп-10 самых частых OKPD2 кодов:\")\n",
    "print(all_okpd2_codes.value_counts().head(10))\n",
    "\n",
    "# Анализ структуры списков OKPD2\n",
    "print(\"\\n=== СТРУКТУРА OKPD2 КОДОВ ===\")\n",
    "okpd2_counts = df['OKPD2_codes'].str.len()\n",
    "print(f\"Количество контрактов с одним OKPD2 кодом: {(okpd2_counts == 1).sum()}\")\n",
    "print(f\"Количество контрактов с несколькими OKPD2 кодами: {(okpd2_counts > 1).sum()}\")\n",
    "print(f\"Максимальное количество OKPD2 кодов в одном контракте: {okpd2_counts.max()}\")\n",
    "\n",
    "# Анализ пропущенных значений\n",
    "print(\"\\n=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Анализ текстовых данных\n",
    "print(\"\\n=== АНАЛИЗ ТЕКСТОВЫХ ДАННЫХ ===\")\n",
    "print(f\"Средняя длина contractSubjectFull: {df['contractSubjectFull'].str.len().mean():.0f} символов\")\n",
    "print(f\"Максимальная длина contractSubjectFull: {df['contractSubjectFull'].str.len().max()} символов\")\n",
    "print(f\"Минимальная длина contractSubjectFull: {df['contractSubjectFull'].str.len().min()} символов\")\n",
    "\n",
    "# Дополнительная информация о структуре данных\n",
    "print(\"\\n=== СТАТИСТИКА ПО КОЛОНКАМ ===\")\n",
    "print(\"Длина regNum:\")\n",
    "print(f\"  Минимальная: {df['regNum'].str.len().min()}\")\n",
    "print(f\"  Максимальная: {df['regNum'].str.len().max()}\")\n",
    "print(f\"  Уникальные длины: {sorted(df['regNum'].str.len().unique())}\")\n",
    "\n",
    "# Примеры данных для лучшего понимания\n",
    "print(\"\\n=== ПРИМЕРЫ ДАННЫХ ===\")\n",
    "print(\"Первые 3 записи:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nЗапись {i+1}:\")\n",
    "    print(f\"  regNum: {df.iloc[i]['regNum']}\")\n",
    "    print(f\"  OKPD2_codes: {df.iloc[i]['OKPD2_codes']}\")\n",
    "    print(f\"  contractSubjectFull (первые 200 символов): {df.iloc[i]['contractSubjectFull'][:200]}...\")\n",
    "\n",
    "# Дополнительный анализ: самые частые комбинации OKPD2 кодов\n",
    "print(\"\\n=== АНАЛИЗ КОМБИНАЦИЙ OKPD2 КОДОВ ===\")\n",
    "# Преобразуем списки в кортежи для анализа уникальных комбинаций\n",
    "okpd2_combinations = df['OKPD2_codes'].apply(tuple)\n",
    "print(f\"Уникальных комбинаций OKPD2 кодов: {okpd2_combinations.nunique()}\")\n",
    "print(\"Топ-5 самых частых комбинаций OKPD2 кодов:\")\n",
    "top_combinations = okpd2_combinations.value_counts().head(5)\n",
    "for combo, count in top_combinations.items():\n",
    "    print(f\"  {list(combo)}: {count} контрактов\")\n",
    "\n",
    "# Анализ распределения количества кодов на контракт\n",
    "print(\"\\n=== РАСПРЕДЕЛЕНИЕ КОЛИЧЕСТВА OKPD2 КОДОВ ===\")\n",
    "count_distribution = okpd2_counts.value_counts().sort_index()\n",
    "for count, freq in count_distribution.items():\n",
    "    print(f\"  {count} код(ов): {freq} контрактов ({freq/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'contractSubject'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'contractSubject'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-2133112634.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Объединение текстовых полей\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contractSubject'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'contractSubjectFull'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Длина текстов после объединения:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'contractSubject'"
     ]
    }
   ],
   "source": [
    "# Объединение текстовых полей\n",
    "df['full_text'] = df['contractSubject'].fillna('') + '. ' + df['contractSubjectFull'].fillna('')\n",
    "\n",
    "print(\"Длина текстов после объединения:\")\n",
    "print(df['full_text'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Базовая очистка текста\n",
    "def clean_text(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return \"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление специальных символов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s\\.]', ' ', text)\n",
    "    # Удаление лишних пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Удаление множественных точек\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['text_clean'] = df['full_text'].apply(clean_text)\n",
    "\n",
    "print(\"Пример очистки текста:\")\n",
    "print(\"ДО:\", df['full_text'].iloc[0][:200])\n",
    "print(\"ПОСЛЕ:\", df['text_clean'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотек для продвинутой обработки (выполнить в терминале)\n",
    "# !pip install pymorphy2 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Скачивание стоп-слов\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "# Доменные стоп-слова\n",
    "domain_stopwords = ['контракт', 'договор', 'приложение', 'пункт', 'статья', \n",
    "                   'далее', 'согласно', 'также', 'например', 'иной', 'другой',\n",
    "                   'обязан', 'обязана', 'обязаны', 'обязано', 'условие', 'следующий']\n",
    "custom_stopwords = set(russian_stopwords + domain_stopwords)\n",
    "\n",
    "def advanced_text_processing(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "    \n",
    "    # Лемматизация\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            lemma = morph.parse(token)[0].normal_form\n",
    "            lemmatized_tokens.append(lemma)\n",
    "        except:\n",
    "            lemmatized_tokens.append(token)\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Применяем к данным\n",
    "print(\"Начата продвинутая обработка текста...\")\n",
    "df['text_processed'] = df['text_clean'].apply(advanced_text_processing)\n",
    "print(\"Обработка завершена!\")\n",
    "\n",
    "print(\"\\nПример продвинутой обработки:\")\n",
    "print(\"ДО:\", df['text_clean'].iloc[0][:150])\n",
    "print(\"ПОСЛЕ:\", df['text_processed'].iloc[0][:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: РАЗМЕТКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== АНАЛИЗ СУЩЕСТВУЮЩЕЙ РАЗМЕТКИ ===\")\n",
    "print(f\"Всего записей: {len(df)}\")\n",
    "print(f\"Записей с OKPD2: {df['OKPD2_codes'].notna().sum()}\")\n",
    "print(f\"Процент размеченных данных: {df['OKPD2_codes'].notna().mean():.2%}\")\n",
    "\n",
    "# Анализ структуры OKPD2 кодов\n",
    "df['okpd_count'] = df['OKPD2_codes'].apply(lambda x: len(x) if x else 0)\n",
    "print(\"\\nРаспределение количества кодов OKPD2 на запись:\")\n",
    "print(df['okpd_count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение и нормализация целевых меток\n",
    "def extract_okpd_label(okpd_codes):\n",
    "    \"\"\"Извлекает основной код OKPD2 для классификации\"\"\"\n",
    "    if not okpd_codes or len(okpd_codes) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Берем первый код из списка\n",
    "    primary_code = okpd_codes[0]\n",
    "    \n",
    "    # Определяем уровень детализации (начинаем с 2-значного кода)\n",
    "    if len(primary_code) >= 2:\n",
    "        return primary_code[:2]  # Первые 2 цифры - раздел\n",
    "    else:\n",
    "        return primary_code\n",
    "\n",
    "# Создаем целевую переменную\n",
    "df['target'] = df['OKPD2_codes'].apply(extract_okpd_label)\n",
    "\n",
    "print(\"Уровень детализации меток:\")\n",
    "print(df['target'].str.len().value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ качества разметки\n",
    "print(\"=== АНАЛИЗ КАЧЕСТВА РАЗМЕТКИ ===\")\n",
    "\n",
    "# Смотрим примеры текстов для разных классов\n",
    "sample_classes = df['target'].value_counts().head(3).index\n",
    "\n",
    "for class_label in sample_classes:\n",
    "    class_texts = df[df['target'] == class_label]['text_clean'].head(2)\n",
    "    print(f\"\\n--- Класс {class_label} ({len(df[df['target'] == class_label])} примеров) ---\")\n",
    "    for i, text in enumerate(class_texts):\n",
    "        print(f\"{i+1}. {text[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка проблем разметки\n",
    "missing_target = df['target'].isna().sum()\n",
    "print(f\"Записей без меток: {missing_target}\")\n",
    "\n",
    "# Анализ малочисленных классов\n",
    "class_counts = df['target'].value_counts()\n",
    "small_classes = class_counts[class_counts < 5]\n",
    "print(f\"Малочисленные классы (менее 5 примеров): {len(small_classes)}\")\n",
    "\n",
    "# Решение: удаляем записи без меток и малочисленные классы\n",
    "df_labeled = df[df['target'].notna()].copy()\n",
    "df_labeled = df_labeled[~df_labeled['target'].isin(small_classes.index)]\n",
    "\n",
    "print(f\"Итоговый размер размеченного датасета: {len(df_labeled)}\")\n",
    "print(f\"Количество классов после фильтрации: {df_labeled['target'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидация разметки\n",
    "print(\"\\n=== ВАЛИДАЦИЯ РАЗМЕТКИ (случайные примеры) ===\")\n",
    "sample_indices = random.sample(range(len(df_labeled)), 5)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = df_labeled.iloc[idx]\n",
    "    print(f\"\\nМетка: {row['target']}\")\n",
    "    print(f\"Текст: {row['text_clean'][:200]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Анализ размеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по классам\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Топ-20 классов\n",
    "top_classes = df_labeled['target'].value_counts().head(20)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=top_classes.values, y=top_classes.index)\n",
    "plt.title('Топ-20 самых частых классов ОКПД2')\n",
    "plt.xlabel('Количество примеров')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Распределение размеров классов\n",
    "class_sizes = df_labeled['target'].value_counts()\n",
    "sns.histplot(class_sizes, bins=30)\n",
    "plt.title('Распределение размеров классов')\n",
    "plt.xlabel('Примеров в классе')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Статистика по классам:\")\n",
    "print(f\"Всего классов: {len(class_sizes)}\")\n",
    "print(f\"Медианный размер класса: {class_sizes.median()}\")\n",
    "print(f\"Минимальный размер: {class_sizes.min()}\")\n",
    "print(f\"Максимальный размер: {class_sizes.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ длины текстов\n",
    "df_labeled['text_length'] = df_labeled['text_processed'].str.split().str.len()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data=df_labeled, x='text_length', bins=50)\n",
    "plt.title('Общее распределение длины текстов')\n",
    "plt.xlabel('Длина текста (слов)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Длина текста по топ-10 классам\n",
    "top_10_classes = class_sizes.head(10).index\n",
    "df_top_classes = df_labeled[df_labeled['target'].isin(top_10_classes)]\n",
    "sns.boxplot(data=df_top_classes, x='target', y='text_length')\n",
    "plt.title('Длина текста по классам (топ-10)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Статистика длины текстов:\")\n",
    "print(df_labeled['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6: Разделение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Стратифицированное разделение\n",
    "X = df_labeled['text_processed']\n",
    "y = df_labeled['target']\n",
    "\n",
    "# 70% train, 15% validation, 15% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(\"=== РАЗДЕЛЕНИЕ НА ВЫБОРКИ ===\")\n",
    "print(f\"Обучающая выборка: {len(X_train)} записей ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"Валидационная выборка: {len(X_val)} записей ({len(X_val)/len(X):.1%})\")\n",
    "print(f\"Тестовая выборка: {len(X_test)} записей ({len(X_test)/len(X):.1%})\")\n",
    "\n",
    "# Проверяем распределение классов в выборках\n",
    "print(\"\\nРаспределение классов по выборкам:\")\n",
    "for name, split in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:\n",
    "    print(f\"{name}: {split.nunique()} классов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7: Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# TF-IDF с разными настройками\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),  # Учитываем отдельные слова и пары\n",
    "    min_df=2,           # Игнорируем очень редкие слова\n",
    "    max_df=0.9,         # Игнорируем очень частые слова\n",
    "    stop_words=list(custom_stopwords)\n",
    ")\n",
    "\n",
    "# Bag-of-Words для сравнения\n",
    "bow_vectorizer = CountVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    stop_words=list(custom_stopwords)\n",
    ")\n",
    "\n",
    "print(\"Векторизаторы созданы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "print(\"Векторизация TF-IDF...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Bag-of-Words\n",
    "print(\"Векторизация Bag-of-Words...\")\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_val_bow = bow_vectorizer.transform(X_val)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nРазмерности матриц признаков:\")\n",
    "print(f\"TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"BOW: {X_train_bow.shape}\")\n",
    "\n",
    "# Сохранение processed данных\n",
    "df_processed = pd.DataFrame({\n",
    "    'text_processed': X,\n",
    "    'target': y\n",
    "})\n",
    "df_processed.to_csv('processed_contracts_data.csv', index=False)\n",
    "print(\"\\nОбработанные данные сохранены в 'processed_contracts_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Чекпойнт №3: Применение простых моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Определение метрик качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "# Для многоклассовой классификации с дисбалансом\n",
    "key_metric = 'f1_macro'  # F1-score (macro average)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Полная оценка модели\"\"\"\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    print(f\"=== {model_name} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Baseline-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print(\"=== BASELINE МОДЕЛИ ===\")\n",
    "\n",
    "# KNN\n",
    "print(\"\\nОбучение KNN...\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "y_pred_knn = knn.predict(X_val_tfidf)\n",
    "knn_metrics = evaluate_model(y_val, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\nОбучение Logistic Regression...\")\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial')\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr.predict(X_val_tfidf)\n",
    "lr_metrics = evaluate_model(y_val, y_pred_lr, \"Logistic Regression\")\n",
    "\n",
    "# Naive Bayes\n",
    "print(\"\\nОбучение Naive Bayes...\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)\n",
    "y_pred_nb = nb.predict(X_val_bow)\n",
    "nb_metrics = evaluate_model(y_val, y_pred_nb, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"=== ПОДБОР ГИПЕРПАРАМЕТРОВ ===\")\n",
    "\n",
    "# Оптимизация логистической регрессии\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial'),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Запуск GridSearch...\")\n",
    "lr_grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {lr_grid.best_params_}\")\n",
    "print(f\"Лучший F1-score на кросс-валидации: {lr_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование лучшей модели\n",
    "best_model = lr_grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_val_tfidf)\n",
    "best_metrics = evaluate_model(y_val, y_pred_best, \"Best Logistic Regression\")\n",
    "\n",
    "# Сравнение всех моделей\n",
    "print(\"\\n=== СРАВНЕНИЕ МОДЕЛЕЙ ===\")\n",
    "models_comparison = pd.DataFrame({\n",
    "    'KNN': knn_metrics,\n",
    "    'LogisticRegression': lr_metrics,\n",
    "    'NaiveBayes': nb_metrics,\n",
    "    'BestModel': best_metrics\n",
    "})\n",
    "\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения моделей\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
    "models_comparison.T[metrics_to_plot].plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Сравнение метрик моделей')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок лучшей модели\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_val, y_pred_best, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45, ax=plt.gca())\n",
    "plt.title('Матрица ошибок - Best Logistic Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ самых частых ошибок\n",
    "error_analysis = pd.DataFrame({\n",
    "    'true': y_val,\n",
    "    'predicted': y_pred_best,\n",
    "    'text': X_val\n",
    "})\n",
    "\n",
    "errors = error_analysis[y_val != y_pred_best]\n",
    "error_counts = errors.groupby(['true', 'predicted']).size().reset_index(name='count')\n",
    "error_counts = error_counts.sort_values('count', ascending=False)\n",
    "\n",
    "print(\"Самые частые ошибки классификации:\")\n",
    "print(error_counts.head(10))\n",
    "\n",
    "print(\"\\nПримеры ошибок:\")\n",
    "for i in range(min(3, len(errors))):\n",
    "    row = errors.iloc[i]\n",
    "    print(f\"\\nОшибка {i+1}:\")\n",
    "    print(f\"Истинный класс: {row['true']}\")\n",
    "    print(f\"Предсказанный класс: {row['predicted']}\")\n",
    "    print(f\"Текст: {row['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Финальные выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ФИНАЛЬНЫЕ ВЫВОДЫ ===\")\n",
    "\n",
    "print(f\"1. РАЗМЕТКА ДАННЫХ:\")\n",
    "print(f\"   - Исходный датасет: {len(df)} записей\")\n",
    "print(f\"   - После очистки и разметки: {len(df_labeled)} записей\")\n",
    "print(f\"   - Количество классов: {df_labeled['target'].nunique()}\")\n",
    "print(f\"   - Сбалансированность: медианный размер класса {class_sizes.median()}\")\n",
    "\n",
    "print(f\"\\n2. КАЧЕСТВО МОДЕЛЕЙ (F1-macro):\")\n",
    "print(f\"   - KNN: {knn_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Naive Bayes: {nb_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Logistic Regression: {lr_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Best Model: {best_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. РЕКОМЕНДАЦИИ:\")\n",
    "print(f\"   - Лучшая модель: {type(best_model).__name__}\")\n",
    "print(f\"   - Ключевая метрика: {key_metric}\")\n",
    "print(f\"   - Основные проблемы: дисбаланс классов, семантически близкие классы\")\n",
    "\n",
    "# Сохранение лучшей модели\n",
    "import joblib\n",
    "\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'vectorizer': tfidf_vectorizer,\n",
    "    'metrics': best_metrics\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, 'best_model_artifacts.pkl')\n",
    "print(f\"\\nЛучшая модель сохранена в 'best_model_artifacts.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
