{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разведочный анализ данных и разметка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 0: Подготовка\n",
    "1. Поскольку коммерческие данные получить быстро не удалось, было принято решение использовать публичные данные, доступные на [госзакупках](https://zakupki.gov.ru/epz/main/public/home.html).\n",
    "2. В связи с таким изменением подхода появилась необходимость переформулирования задачи, теперь она сформулирована так: \"Классификация договора в зависимости от предмета по второму уровню ОКПД2\". Классификатор ОКПД2 можно получить, например, [здесь](https://www.consultant.ru/document/cons_doc_LAW_163703/). Таким образом, цель изменилась до: по разделу предмета договора вернуть второй уровень кода ОКПД2.\n",
    "Важное замечание: поскольку предметов договора в данном случае может быть много, то мы имеем дело с многоклассовой классификацией.\n",
    "3. Датасет состоит из 200057 записей в формате JSON, содержащие три поля \"regNum\" - реестровый номер контракта, \"contractSubjectFull\" - полный текст предмета договора, \"OKPD2_codes\" - набор ОКПД2 кодов из договора. Датасет расположени по [адресу](https://www.kaggle.com/datasets/aldarovalexander/contract). Сам датасет был получен путем парсинга части исполненных договоров за 2022 год, которые бы имели формат верный DOCX и разбора формализованной части договоров. Часть процесса получения, например, из графического представления договора верного текста предмета в данном исследовании опущена, поскольку для целей самого исследования не представляет интереса.\n",
    "4. Блокнот доступен в [колабе](https://colab.research.google.com/github/aldarovav/YearProject/blob/main/analysis.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Импорт библиотек и настройка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Библиотеки загружены\n",
      "Текущая рабочая директория: /content\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import io\n",
    "import requests\n",
    "import json\n",
    "import kagglehub\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from io import StringIO\n",
    "from collections import Counter\n",
    "\n",
    "# Настройка отображения\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', None)\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Библиотеки загружены\")\n",
    "print(\"Текущая рабочая директория:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Загрузка и первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Colab cache for faster access to the 'contract' dataset.\n",
      "First 5 records:                 regNum  \\\n",
      "0  0166300031414000004   \n",
      "1  0324300007314000014   \n",
      "2  0366300032914000027   \n",
      "3  1010501417722000033   \n",
      "4  1010501746721000017   \n",
      "\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       contractSubjectFull  \\\n",
      "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект) в соответствии с условиями настоящего контракта и локальной сметой (приложение №1), являющейся неотъемлемой частью настоящего контракта. 1.2. Подрядчик обязуется выполнить работы, указанные в пункте 1.1. контракта, своими силами или с привлечением субподрядных организаций. 2.   \n",
      "1  Исполнитель обязуется выполнить работу согласно Приложению № к Контракту и сдать ее результат Заказчику, а Заказчик обязуется принять результат работы и оплатить его. Качество работы Качество выполненной работы должно соответствовать требованиям, указанным в Приложении № к Контракту. Гарантийный срок, установленный на результат работы, указан в Приложении № к Контракту. Гарантийный срок исчисляется с момента, когда по условиям Контракта результат выполненной работы принят или должен быть принят Заказчиком. Гарантийный срок продлевается на период, в течение которого Заказчик не мог пользоваться результатом работы из-за обнаруженных в нем недостатков, при условии, что Исполнитель был письменно извещен Заказчиком об обнаружении недостатков в срок, предусмотренный Контрактом. Гарантия качества распространяется на все, что составляет результат работы. В случае предъявления Заказчиком требования о безвозмездном устранении недостатков выполненной работы согласно п. 1 ст. 723 ГК РФ они должны быть устранены Исполнителем в срок 10 (десяти) календарных дней с момента получения этого требования. Заказчик вправе устранять недостатки выполненной Исполнителем работы самостоятельно или с привлечением третьих лиц и требовать от Исполнителя возмещения расходов на их устранение. Исполнитель обязан возместить расходы Заказчика на устранение недостатков выполненной работы в срок 10 (десяти) календарных дней. Расходы подлежат возмещению при условии представления Заказчиком подтверждающих их документов. Если отступления в работе от условий Контракта или иные недостатки результата работы не были устранены в установленный Контрактом срок либо являются существенными и неустранимыми, Заказчик вправе отказаться от исполнения Контракта и потребовать возмещения причиненных убытков.   \n",
      "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          1.1. По настоящему контракту поставщик обязуется поставить и передать заказчику в срок, предусмотренный настоящим контрактом, лекарственные препараты (далее - товар) в соответствии со спецификацией (приложение № 1), являющейся неотъемлемой частью настоящего контракта, а заказчик обязуется принять и оплатить товар на условиях, предусмотренных настоящим контрактом. 1.2. Наименование, единица измерения, количество,   \n",
      "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1.1. Поставщик обязуется осуществить поставку многофункциональных устройств (МФУ) (далее – Товар) согласно Спецификации (Приложение № 1 к настоящему контракту), а Заказчик в свою очередь обязуется принять Товар и оплатить его в соответствии с условиями настоящего контракта. 1.2. Место поставки Товара: Республика Адыгея, г. Майкоп, ул. Первомайская, 191. 1.3. Срок поставки Товара: в течение 15 (пятнадцать) рабочих дней со дня заключения контракта. 2.   \n",
      "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             ГОСУДАРСТВЕННЫЙ КОНТРАКТ № 08/23 Идентификационный код закупки- 211010501746701050100100300011723244 г. Майкоп\\t «14» сентября 2021 года Отдел Министерства внутренних дел Российской Федерации по городу Майкопу, именуемый в дальнейшем  \\   \n",
      "\n",
      "  OKPD2_codes  \n",
      "0        [43]  \n",
      "1        [71]  \n",
      "2        [21]  \n",
      "3        [26]  \n",
      "4        [17]  \n",
      "Data types: regNum                 object\n",
      "contractSubjectFull    object\n",
      "OKPD2_codes            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "from kagglehub import KaggleDatasetAdapter\n",
    "import pandas as pd\n",
    "\n",
    "# Указываем конкретный файл для загрузки\n",
    "file_path = \"contracts_dataset_unique.json\"\n",
    "\n",
    "# Сначала получим путь к файлу\n",
    "dataset_path = kagglehub.dataset_download(\"aldarovalexander/contract\")\n",
    "full_file_path = f\"{dataset_path}/{file_path}\"\n",
    "\n",
    "# Загрузим JSON с указанием dtype\n",
    "df = pd.read_json(full_file_path, dtype={'regNum': str})\n",
    "\n",
    "print(\"First 5 records:\", df.head())\n",
    "print(\"Data types:\", df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>regNum</th>\n",
       "      <td>0166300031414000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contractSubjectFull</th>\n",
       "      <td>1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект) в соответствии с условиями настоящего контракта и локальной сметой (приложение №1), являющейся неотъемлемой частью настоящего контракта. 1.2. Подрядчик обязуется выполнить работы, указанные в пункте 1.1. контракта, своими силами или с привлечением субподрядных организаций. 2.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OKPD2_codes</th>\n",
       "      <td>[43]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div><br><label><b>dtype:</b> object</label>"
      ],
      "text/plain": [
       "regNum                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            0166300031414000004\n",
       "contractSubjectFull    1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект) в соответствии с условиями настоящего контракта и локальной сметой (приложение №1), являющейся неотъемлемой частью настоящего контракта. 1.2. Подрядчик обязуется выполнить работы, указанные в пункте 1.1. контракта, своими силами или с привлечением субподрядных организаций. 2.\n",
       "OKPD2_codes                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      [43]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ ===\n",
      "Размер датасета: (199913, 3)\n",
      "Колонки: ['regNum', 'contractSubjectFull', 'OKPD2_codes']\n",
      "\n",
      "Типы данных:\n",
      "regNum                 object\n",
      "contractSubjectFull    object\n",
      "OKPD2_codes            object\n",
      "dtype: object\n",
      "\n",
      "=== ДЕТАЛЬНЫЙ АНАЛИЗ ===\n",
      "Общее количество записей: 199913\n",
      "Количество уникальных номеров контрактов: 199913\n",
      "Неуникальные номера контрактов: Empty DataFrame\n",
      "Columns: [regNum, contractSubjectFull, OKPD2_codes]\n",
      "Index: []\n",
      "\n",
      "=== АНАЛИЗ OKPD2 КОДОВ ===\n",
      "Всего OKPD2 кодов (с повторениями): 211887\n",
      "Уникальных OKPD2 кодов: 84\n",
      "\n",
      "Топ-10 самых частых OKPD2 кодов:\n",
      "OKPD2_codes\n",
      "21    36805\n",
      "10    28412\n",
      "32    21144\n",
      "26    10968\n",
      "20     7493\n",
      "01     7327\n",
      "43     6795\n",
      "17     6455\n",
      "22     6036\n",
      "68     4521\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== СТРУКТУРА OKPD2 КОДОВ ===\n",
      "Количество контрактов с одним OKPD2 кодом: 191144\n",
      "Количество контрактов с несколькими OKPD2 кодами: 8769\n",
      "Максимальное количество OKPD2 кодов в одном контракте: 11\n",
      "\n",
      "=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===\n",
      "regNum                 0\n",
      "contractSubjectFull    0\n",
      "OKPD2_codes            0\n",
      "dtype: int64\n",
      "\n",
      "=== АНАЛИЗ ТЕКСТОВЫХ ДАННЫХ ===\n",
      "Средняя длина contractSubjectFull: 872 символов\n",
      "Максимальная длина contractSubjectFull: 9398 символов\n",
      "Минимальная длина contractSubjectFull: 1 символов\n",
      "\n",
      "=== СТАТИСТИКА ПО КОЛОНКАМ ===\n",
      "Длина regNum:\n",
      "  Минимальная: 19\n",
      "  Максимальная: 19\n",
      "  Уникальные длины: [np.int64(19)]\n",
      "\n",
      "=== ПРИМЕРЫ ДАННЫХ ===\n",
      "Первые 3 записи:\n",
      "\n",
      "Запись 1:\n",
      "  regNum: 0166300031414000004\n",
      "  OKPD2_codes: ['43']\n",
      "  contractSubjectFull (первые 200 символов): 1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект...\n",
      "\n",
      "Запись 2:\n",
      "  regNum: 0324300007314000014\n",
      "  OKPD2_codes: ['71']\n",
      "  contractSubjectFull (первые 200 символов): Исполнитель обязуется выполнить работу согласно Приложению № к Контракту и сдать ее результат Заказчику, а Заказчик обязуется принять результат работы и оплатить его. Качество работы Качество выполнен...\n",
      "\n",
      "Запись 3:\n",
      "  regNum: 0366300032914000027\n",
      "  OKPD2_codes: ['21']\n",
      "  contractSubjectFull (первые 200 символов): 1.1. По настоящему контракту поставщик обязуется поставить и передать заказчику в срок, предусмотренный настоящим контрактом, лекарственные препараты (далее - товар) в соответствии со спецификацией (п...\n",
      "\n",
      "=== АНАЛИЗ КОМБИНАЦИЙ OKPD2 КОДОВ ===\n",
      "Уникальных комбинаций OKPD2 кодов: 1046\n",
      "Топ-5 самых частых комбинаций OKPD2 кодов:\n",
      "  ['21']: 36052 контрактов\n",
      "  ['10']: 26235 контрактов\n",
      "  ['32']: 19288 контрактов\n",
      "  ['26']: 10257 контрактов\n",
      "  ['43']: 6596 контрактов\n",
      "\n",
      "=== РАСПРЕДЕЛЕНИЕ КОЛИЧЕСТВА OKPD2 КОДОВ ===\n",
      "  1 код(ов): 191144 контрактов (95.6%)\n",
      "  2 код(ов): 6674 контрактов (3.3%)\n",
      "  3 код(ов): 1354 контрактов (0.7%)\n",
      "  4 код(ов): 514 контрактов (0.3%)\n",
      "  5 код(ов): 142 контрактов (0.1%)\n",
      "  6 код(ов): 52 контрактов (0.0%)\n",
      "  7 код(ов): 22 контрактов (0.0%)\n",
      "  8 код(ов): 4 контрактов (0.0%)\n",
      "  9 код(ов): 4 контрактов (0.0%)\n",
      "  11 код(ов): 3 контрактов (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# Используем новый метод dataset_load()\n",
    "\n",
    "print(\"=== ПЕРВИЧНЫЙ АНАЛИЗ ДАННЫХ ===\")\n",
    "print(f\"Размер датасета: {df.shape}\")\n",
    "print(f\"Колонки: {list(df.columns)}\")\n",
    "print(\"\\nТипы данных:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Преобразуем regNum в строковый тип\n",
    "df['regNum'] = df['regNum'].astype(str)\n",
    "\n",
    "# Более детальный анализ\n",
    "print(\"\\n=== ДЕТАЛЬНЫЙ АНАЛИЗ ===\")\n",
    "print(f\"Общее количество записей: {len(df)}\")\n",
    "print(f\"Количество уникальных номеров контрактов: {df['regNum'].nunique()}\")\n",
    "print(f\"Неуникальные номера контрактов: {df[df.duplicated('regNum', keep=False)]}\")\n",
    "\n",
    "# Правильный анализ OKPD2 кодов (списков)\n",
    "print(\"\\n=== АНАЛИЗ OKPD2 КОДОВ ===\")\n",
    "# Развернем списки OKPD2 кодов для анализа\n",
    "all_okpd2_codes = df['OKPD2_codes'].explode()\n",
    "print(f\"Всего OKPD2 кодов (с повторениями): {len(all_okpd2_codes)}\")\n",
    "print(f\"Уникальных OKPD2 кодов: {all_okpd2_codes.nunique()}\")\n",
    "print(\"\\nТоп-10 самых частых OKPD2 кодов:\")\n",
    "print(all_okpd2_codes.value_counts().head(10))\n",
    "\n",
    "# Анализ структуры списков OKPD2\n",
    "print(\"\\n=== СТРУКТУРА OKPD2 КОДОВ ===\")\n",
    "okpd2_counts = df['OKPD2_codes'].str.len()\n",
    "print(f\"Количество контрактов с одним OKPD2 кодом: {(okpd2_counts == 1).sum()}\")\n",
    "print(f\"Количество контрактов с несколькими OKPD2 кодами: {(okpd2_counts > 1).sum()}\")\n",
    "print(f\"Максимальное количество OKPD2 кодов в одном контракте: {okpd2_counts.max()}\")\n",
    "\n",
    "# Анализ пропущенных значений\n",
    "print(\"\\n=== ПРОПУЩЕННЫЕ ЗНАЧЕНИЯ ===\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Анализ текстовых данных\n",
    "print(\"\\n=== АНАЛИЗ ТЕКСТОВЫХ ДАННЫХ ===\")\n",
    "print(f\"Средняя длина contractSubjectFull: {df['contractSubjectFull'].str.len().mean():.0f} символов\")\n",
    "print(f\"Максимальная длина contractSubjectFull: {df['contractSubjectFull'].str.len().max()} символов\")\n",
    "print(f\"Минимальная длина contractSubjectFull: {df['contractSubjectFull'].str.len().min()} символов\")\n",
    "\n",
    "# Дополнительная информация о структуре данных\n",
    "print(\"\\n=== СТАТИСТИКА ПО КОЛОНКАМ ===\")\n",
    "print(\"Длина regNum:\")\n",
    "print(f\"  Минимальная: {df['regNum'].str.len().min()}\")\n",
    "print(f\"  Максимальная: {df['regNum'].str.len().max()}\")\n",
    "print(f\"  Уникальные длины: {sorted(df['regNum'].str.len().unique())}\")\n",
    "\n",
    "# Примеры данных для лучшего понимания\n",
    "print(\"\\n=== ПРИМЕРЫ ДАННЫХ ===\")\n",
    "print(\"Первые 3 записи:\")\n",
    "for i in range(3):\n",
    "    print(f\"\\nЗапись {i+1}:\")\n",
    "    print(f\"  regNum: {df.iloc[i]['regNum']}\")\n",
    "    print(f\"  OKPD2_codes: {df.iloc[i]['OKPD2_codes']}\")\n",
    "    print(f\"  contractSubjectFull (первые 200 символов): {df.iloc[i]['contractSubjectFull'][:200]}...\")\n",
    "\n",
    "# Дополнительный анализ: самые частые комбинации OKPD2 кодов\n",
    "print(\"\\n=== АНАЛИЗ КОМБИНАЦИЙ OKPD2 КОДОВ ===\")\n",
    "# Преобразуем списки в кортежи для анализа уникальных комбинаций\n",
    "okpd2_combinations = df['OKPD2_codes'].apply(tuple)\n",
    "print(f\"Уникальных комбинаций OKPD2 кодов: {okpd2_combinations.nunique()}\")\n",
    "print(\"Топ-5 самых частых комбинаций OKPD2 кодов:\")\n",
    "top_combinations = okpd2_combinations.value_counts().head(5)\n",
    "for combo, count in top_combinations.items():\n",
    "    print(f\"  {list(combo)}: {count} контрактов\")\n",
    "\n",
    "# Анализ распределения количества кодов на контракт\n",
    "print(\"\\n=== РАСПРЕДЕЛЕНИЕ КОЛИЧЕСТВА OKPD2 КОДОВ ===\")\n",
    "count_distribution = okpd2_counts.value_counts().sort_index()\n",
    "for count, freq in count_distribution.items():\n",
    "    print(f\"  {count} код(ов): {freq} контрактов ({freq/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: Предобработка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Длина текстов после объединения:\n",
      "count    199913.000000\n",
      "mean        872.184080\n",
      "std         652.309824\n",
      "min           1.000000\n",
      "25%         472.000000\n",
      "50%         687.000000\n",
      "75%        1048.000000\n",
      "max        9398.000000\n",
      "Name: full_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Объединение текстовых полей\n",
    "df['full_text'] = df['contractSubjectFull'].fillna('')\n",
    "\n",
    "print(\"Длина текстов после объединения:\")\n",
    "print(df['full_text'].str.len().describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Пример очистки текста:\n",
      "ДО: 1.1. Подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома №6, расположенного по адресу: Тульская область, Ленинский район, п. Молодежный, ул. Центральная (далее - объект\n",
      "ПОСЛЕ: 1.1. подрядчик обязуется выполнить работы по ремонту кровли и утеплению труб жилого дома 6 расположенного по адресу тульская область ленинский район п. молодежный ул. центральная далее объект в соотве\n"
     ]
    }
   ],
   "source": [
    "# Базовая очистка текста\n",
    "def clean_text(text):\n",
    "    if pd.isna(text) or text == '':\n",
    "        return \"\"\n",
    "    # Приведение к нижнему регистру\n",
    "    text = text.lower()\n",
    "    # Удаление специальных символов\n",
    "    text = re.sub(r'[^a-zA-Zа-яА-Я0-9\\s\\.]', ' ', text)\n",
    "    # Удаление лишних пробелов\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Удаление множественных точек\n",
    "    text = re.sub(r'\\.{2,}', '.', text)\n",
    "    return text.strip()\n",
    "\n",
    "df['text_clean'] = df['full_text'].apply(clean_text)\n",
    "\n",
    "print(\"Пример очистки текста:\")\n",
    "print(\"ДО:\", df['full_text'].iloc[0][:200])\n",
    "print(\"ПОСЛЕ:\", df['text_clean'].iloc[0][:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Установка библиотек для продвинутой обработки (выполнить в терминале)\n",
    "# !pip install pymorphy2 nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymorphy2 in /usr/local/lib/python3.12/dist-packages (0.9.1)\n",
      "Requirement already satisfied: dawg-python>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from pymorphy2) (0.7.2)\n",
      "Requirement already satisfied: pymorphy2-dicts-ru<3.0,>=2.4 in /usr/local/lib/python3.12/dist-packages (from pymorphy2) (2.4.417127.4579844)\n",
      "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.12/dist-packages (from pymorphy2) (0.6.2)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
      "Начата продвинутая обработка текста...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'inspect' has no attribute 'getargspec'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-4173182561.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;31m# Применяем к данным\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Начата продвинутая обработка текста...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_processed'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text_clean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvanced_text_processing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Обработка завершена!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4922\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4923\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4924\u001b[0;31m         ).apply()\n\u001b[0m\u001b[1;32m   4925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4926\u001b[0m     def _reindex_indexer(\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;31m# self.func is Callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1505\u001b[0m         \u001b[0;31m#  Categorical (GH51645).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCategoricalDtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m         mapped = obj._map_values(\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0mmapper\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         )\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    919\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malgorithms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfinal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1742\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mna_action\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1743\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1744\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m         return lib.map_infer_mask(\n",
      "\u001b[0;32mlib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-4173182561.py\u001b[0m in \u001b[0;36madvanced_text_processing\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;31m# Лемматизация\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mmorph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpymorphy2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMorphAnalyzer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlemmatized_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, lang, result_type, units, probability_estimator_cls, char_substitutes)\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result_type_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_char_substitutes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchar_substitutes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_init_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_unbound\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m_init_units\u001b[0;34m(self, units_unbound)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0munit\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_units\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/analyzer.py\u001b[0m in \u001b[0;36m_bound_unit\u001b[0;34m(self, unit)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_bound_unit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 246\u001b[0;31m         \u001b[0munit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    247\u001b[0m         \u001b[0munit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36mclone\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_lower\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseen_parses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36m_get_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;34m\"\"\" Return a dict with the parameters for this analyzer unit. \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         return dict(\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_param_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         )\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pymorphy2/units/base.py\u001b[0m in \u001b[0;36m_get_param_names\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvarargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'inspect' has no attribute 'getargspec'"
     ]
    }
   ],
   "source": [
    "!pip install pymorphy2\n",
    "!pip install nltk\n",
    "import pymorphy2\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Скачивание стоп-слов\n",
    "nltk.download('stopwords')\n",
    "russian_stopwords = stopwords.words('russian')\n",
    "\n",
    "# Доменные стоп-слова\n",
    "domain_stopwords = ['контракт', 'договор', 'приложение', 'пункт', 'статья', \n",
    "                   'далее', 'согласно', 'также', 'например', 'иной', 'другой',\n",
    "                   'обязан', 'обязана', 'обязаны', 'обязано', 'условие', 'следующий']\n",
    "custom_stopwords = set(russian_stopwords + domain_stopwords)\n",
    "\n",
    "def advanced_text_processing(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    \n",
    "    # Токенизация\n",
    "    tokens = text.split()\n",
    "    \n",
    "    # Удаление стоп-слов\n",
    "    tokens = [token for token in tokens if token not in custom_stopwords]\n",
    "    \n",
    "    # Лемматизация\n",
    "    morph = pymorphy2.MorphAnalyzer()\n",
    "    lemmatized_tokens = []\n",
    "    for token in tokens:\n",
    "        try:\n",
    "            lemma = morph.parse(token)[0].normal_form\n",
    "            lemmatized_tokens.append(lemma)\n",
    "        except:\n",
    "            lemmatized_tokens.append(token)\n",
    "    \n",
    "    return ' '.join(lemmatized_tokens)\n",
    "\n",
    "# Применяем к данным\n",
    "print(\"Начата продвинутая обработка текста...\")\n",
    "df['text_processed'] = df['text_clean'].apply(advanced_text_processing)\n",
    "print(\"Обработка завершена!\")\n",
    "\n",
    "print(\"\\nПример продвинутой обработки:\")\n",
    "print(\"ДО:\", df['text_clean'].iloc[0][:150])\n",
    "print(\"ПОСЛЕ:\", df['text_processed'].iloc[0][:150])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: РАЗМЕТКА ДАННЫХ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== АНАЛИЗ СУЩЕСТВУЮЩЕЙ РАЗМЕТКИ ===\")\n",
    "print(f\"Всего записей: {len(df)}\")\n",
    "print(f\"Записей с OKPD2: {df['OKPD2_codes'].notna().sum()}\")\n",
    "print(f\"Процент размеченных данных: {df['OKPD2_codes'].notna().mean():.2%}\")\n",
    "\n",
    "# Анализ структуры OKPD2 кодов\n",
    "df['okpd_count'] = df['OKPD2_codes'].apply(lambda x: len(x) if x else 0)\n",
    "print(\"\\nРаспределение количества кодов OKPD2 на запись:\")\n",
    "print(df['okpd_count'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Извлечение и нормализация целевых меток\n",
    "def extract_okpd_label(okpd_codes):\n",
    "    \"\"\"Извлекает основной код OKPD2 для классификации\"\"\"\n",
    "    if not okpd_codes or len(okpd_codes) == 0:\n",
    "        return None\n",
    "    \n",
    "    # Берем первый код из списка\n",
    "    primary_code = okpd_codes[0]\n",
    "    \n",
    "    # Определяем уровень детализации (начинаем с 2-значного кода)\n",
    "    if len(primary_code) >= 2:\n",
    "        return primary_code[:2]  # Первые 2 цифры - раздел\n",
    "    else:\n",
    "        return primary_code\n",
    "\n",
    "# Создаем целевую переменную\n",
    "df['target'] = df['OKPD2_codes'].apply(extract_okpd_label)\n",
    "\n",
    "print(\"Уровень детализации меток:\")\n",
    "print(df['target'].str.len().value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ качества разметки\n",
    "print(\"=== АНАЛИЗ КАЧЕСТВА РАЗМЕТКИ ===\")\n",
    "\n",
    "# Смотрим примеры текстов для разных классов\n",
    "sample_classes = df['target'].value_counts().head(3).index\n",
    "\n",
    "for class_label in sample_classes:\n",
    "    class_texts = df[df['target'] == class_label]['text_clean'].head(2)\n",
    "    print(f\"\\n--- Класс {class_label} ({len(df[df['target'] == class_label])} примеров) ---\")\n",
    "    for i, text in enumerate(class_texts):\n",
    "        print(f\"{i+1}. {text[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обработка проблем разметки\n",
    "missing_target = df['target'].isna().sum()\n",
    "print(f\"Записей без меток: {missing_target}\")\n",
    "\n",
    "# Анализ малочисленных классов\n",
    "class_counts = df['target'].value_counts()\n",
    "small_classes = class_counts[class_counts < 5]\n",
    "print(f\"Малочисленные классы (менее 5 примеров): {len(small_classes)}\")\n",
    "\n",
    "# Решение: удаляем записи без меток и малочисленные классы\n",
    "df_labeled = df[df['target'].notna()].copy()\n",
    "df_labeled = df_labeled[~df_labeled['target'].isin(small_classes.index)]\n",
    "\n",
    "print(f\"Итоговый размер размеченного датасета: {len(df_labeled)}\")\n",
    "print(f\"Количество классов после фильтрации: {df_labeled['target'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Валидация разметки\n",
    "print(\"\\n=== ВАЛИДАЦИЯ РАЗМЕТКИ (случайные примеры) ===\")\n",
    "sample_indices = random.sample(range(len(df_labeled)), 5)\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = df_labeled.iloc[idx]\n",
    "    print(f\"\\nМетка: {row['target']}\")\n",
    "    print(f\"Текст: {row['text_clean'][:200]}...\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Анализ размеченных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Статистика по классам\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "# Топ-20 классов\n",
    "top_classes = df_labeled['target'].value_counts().head(20)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=top_classes.values, y=top_classes.index)\n",
    "plt.title('Топ-20 самых частых классов ОКПД2')\n",
    "plt.xlabel('Количество примеров')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Распределение размеров классов\n",
    "class_sizes = df_labeled['target'].value_counts()\n",
    "sns.histplot(class_sizes, bins=30)\n",
    "plt.title('Распределение размеров классов')\n",
    "plt.xlabel('Примеров в классе')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Статистика по классам:\")\n",
    "print(f\"Всего классов: {len(class_sizes)}\")\n",
    "print(f\"Медианный размер класса: {class_sizes.median()}\")\n",
    "print(f\"Минимальный размер: {class_sizes.min()}\")\n",
    "print(f\"Максимальный размер: {class_sizes.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ длины текстов\n",
    "df_labeled['text_length'] = df_labeled['text_processed'].str.split().str.len()\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(data=df_labeled, x='text_length', bins=50)\n",
    "plt.title('Общее распределение длины текстов')\n",
    "plt.xlabel('Длина текста (слов)')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "# Длина текста по топ-10 классам\n",
    "top_10_classes = class_sizes.head(10).index\n",
    "df_top_classes = df_labeled[df_labeled['target'].isin(top_10_classes)]\n",
    "sns.boxplot(data=df_top_classes, x='target', y='text_length')\n",
    "plt.title('Длина текста по классам (топ-10)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Статистика длины текстов:\")\n",
    "print(df_labeled['text_length'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 6: Разделение на выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Стратифицированное разделение\n",
    "X = df_labeled['text_processed']\n",
    "y = df_labeled['target']\n",
    "\n",
    "# 70% train, 15% validation, 15% test\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.176, random_state=42, stratify=y_temp  # 0.176 * 0.85 ≈ 0.15\n",
    ")\n",
    "\n",
    "print(\"=== РАЗДЕЛЕНИЕ НА ВЫБОРКИ ===\")\n",
    "print(f\"Обучающая выборка: {len(X_train)} записей ({len(X_train)/len(X):.1%})\")\n",
    "print(f\"Валидационная выборка: {len(X_val)} записей ({len(X_val)/len(X):.1%})\")\n",
    "print(f\"Тестовая выборка: {len(X_test)} записей ({len(X_test)/len(X):.1%})\")\n",
    "\n",
    "# Проверяем распределение классов в выборках\n",
    "print(\"\\nРаспределение классов по выборкам:\")\n",
    "for name, split in [('Train', y_train), ('Val', y_val), ('Test', y_test)]:\n",
    "    print(f\"{name}: {split.nunique()} классов\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 7: Векторизация текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "# TF-IDF с разными настройками\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),  # Учитываем отдельные слова и пары\n",
    "    min_df=2,           # Игнорируем очень редкие слова\n",
    "    max_df=0.9,         # Игнорируем очень частые слова\n",
    "    stop_words=list(custom_stopwords)\n",
    ")\n",
    "\n",
    "# Bag-of-Words для сравнения\n",
    "bow_vectorizer = CountVectorizer(\n",
    "    max_features=8000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.9,\n",
    "    stop_words=list(custom_stopwords)\n",
    ")\n",
    "\n",
    "print(\"Векторизаторы созданы\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF\n",
    "print(\"Векторизация TF-IDF...\")\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Bag-of-Words\n",
    "print(\"Векторизация Bag-of-Words...\")\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_val_bow = bow_vectorizer.transform(X_val)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "print(f\"\\nРазмерности матриц признаков:\")\n",
    "print(f\"TF-IDF: {X_train_tfidf.shape}\")\n",
    "print(f\"BOW: {X_train_bow.shape}\")\n",
    "\n",
    "# Сохранение processed данных\n",
    "df_processed = pd.DataFrame({\n",
    "    'text_processed': X,\n",
    "    'target': y\n",
    "})\n",
    "df_processed.to_csv('processed_contracts_data.csv', index=False)\n",
    "print(\"\\nОбработанные данные сохранены в 'processed_contracts_data.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Чекпойнт №3: Применение простых моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 1: Определение метрик качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
    "\n",
    "# Для многоклассовой классификации с дисбалансом\n",
    "key_metric = 'f1_macro'  # F1-score (macro average)\n",
    "\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    \"\"\"Полная оценка модели\"\"\"\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision_macro': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'recall_macro': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_macro': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
    "        'f1_weighted': f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    }\n",
    "    \n",
    "    print(f\"=== {model_name} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"{metric}: {value:.4f}\")\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 2: Baseline-модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "print(\"=== BASELINE МОДЕЛИ ===\")\n",
    "\n",
    "# KNN\n",
    "print(\"\\nОбучение KNN...\")\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_tfidf, y_train)\n",
    "y_pred_knn = knn.predict(X_val_tfidf)\n",
    "knn_metrics = evaluate_model(y_val, y_pred_knn, \"KNN\")\n",
    "\n",
    "# Logistic Regression\n",
    "print(\"\\nОбучение Logistic Regression...\")\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial')\n",
    "lr.fit(X_train_tfidf, y_train)\n",
    "y_pred_lr = lr.predict(X_val_tfidf)\n",
    "lr_metrics = evaluate_model(y_val, y_pred_lr, \"Logistic Regression\")\n",
    "\n",
    "# Naive Bayes\n",
    "print(\"\\nОбучение Naive Bayes...\")\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_bow, y_train)\n",
    "y_pred_nb = nb.predict(X_val_bow)\n",
    "nb_metrics = evaluate_model(y_val, y_pred_nb, \"Naive Bayes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 3: Подбор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "print(\"=== ПОДБОР ГИПЕРПАРАМЕТРОВ ===\")\n",
    "\n",
    "# Оптимизация логистической регрессии\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000, multi_class='multinomial'),\n",
    "    param_grid,\n",
    "    cv=3,\n",
    "    scoring='f1_macro',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Запуск GridSearch...\")\n",
    "lr_grid.fit(X_train_tfidf, y_train)\n",
    "\n",
    "print(f\"Лучшие параметры: {lr_grid.best_params_}\")\n",
    "print(f\"Лучший F1-score на кросс-валидации: {lr_grid.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 4: Анализ результатов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Тестирование лучшей модели\n",
    "best_model = lr_grid.best_estimator_\n",
    "y_pred_best = best_model.predict(X_val_tfidf)\n",
    "best_metrics = evaluate_model(y_val, y_pred_best, \"Best Logistic Regression\")\n",
    "\n",
    "# Сравнение всех моделей\n",
    "print(\"\\n=== СРАВНЕНИЕ МОДЕЛЕЙ ===\")\n",
    "models_comparison = pd.DataFrame({\n",
    "    'KNN': knn_metrics,\n",
    "    'LogisticRegression': lr_metrics,\n",
    "    'NaiveBayes': nb_metrics,\n",
    "    'BestModel': best_metrics\n",
    "})\n",
    "\n",
    "models_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Визуализация сравнения моделей\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']\n",
    "models_comparison.T[metrics_to_plot].plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Сравнение метрик моделей')\n",
    "plt.ylabel('Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Матрица ошибок лучшей модели\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "cm = confusion_matrix(y_val, y_pred_best, labels=best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_model.classes_)\n",
    "disp.plot(cmap='Blues', xticks_rotation=45, ax=plt.gca())\n",
    "plt.title('Матрица ошибок - Best Logistic Regression')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Анализ самых частых ошибок\n",
    "error_analysis = pd.DataFrame({\n",
    "    'true': y_val,\n",
    "    'predicted': y_pred_best,\n",
    "    'text': X_val\n",
    "})\n",
    "\n",
    "errors = error_analysis[y_val != y_pred_best]\n",
    "error_counts = errors.groupby(['true', 'predicted']).size().reset_index(name='count')\n",
    "error_counts = error_counts.sort_values('count', ascending=False)\n",
    "\n",
    "print(\"Самые частые ошибки классификации:\")\n",
    "print(error_counts.head(10))\n",
    "\n",
    "print(\"\\nПримеры ошибок:\")\n",
    "for i in range(min(3, len(errors))):\n",
    "    row = errors.iloc[i]\n",
    "    print(f\"\\nОшибка {i+1}:\")\n",
    "    print(f\"Истинный класс: {row['true']}\")\n",
    "    print(f\"Предсказанный класс: {row['predicted']}\")\n",
    "    print(f\"Текст: {row['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Шаг 5: Финальные выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== ФИНАЛЬНЫЕ ВЫВОДЫ ===\")\n",
    "\n",
    "print(f\"1. РАЗМЕТКА ДАННЫХ:\")\n",
    "print(f\"   - Исходный датасет: {len(df)} записей\")\n",
    "print(f\"   - После очистки и разметки: {len(df_labeled)} записей\")\n",
    "print(f\"   - Количество классов: {df_labeled['target'].nunique()}\")\n",
    "print(f\"   - Сбалансированность: медианный размер класса {class_sizes.median()}\")\n",
    "\n",
    "print(f\"\\n2. КАЧЕСТВО МОДЕЛЕЙ (F1-macro):\")\n",
    "print(f\"   - KNN: {knn_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Naive Bayes: {nb_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Logistic Regression: {lr_metrics['f1_macro']:.4f}\")\n",
    "print(f\"   - Best Model: {best_metrics['f1_macro']:.4f}\")\n",
    "\n",
    "print(f\"\\n3. РЕКОМЕНДАЦИИ:\")\n",
    "print(f\"   - Лучшая модель: {type(best_model).__name__}\")\n",
    "print(f\"   - Ключевая метрика: {key_metric}\")\n",
    "print(f\"   - Основные проблемы: дисбаланс классов, семантически близкие классы\")\n",
    "\n",
    "# Сохранение лучшей модели\n",
    "import joblib\n",
    "\n",
    "model_artifacts = {\n",
    "    'model': best_model,\n",
    "    'vectorizer': tfidf_vectorizer,\n",
    "    'metrics': best_metrics\n",
    "}\n",
    "\n",
    "joblib.dump(model_artifacts, 'best_model_artifacts.pkl')\n",
    "print(f\"\\nЛучшая модель сохранена в 'best_model_artifacts.pkl'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
